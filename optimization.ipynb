{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using StaticArrays\n",
    "using Random\n",
    "using Plots\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia is just in time (JIT) compiled, so the first time you run code there will be a penalty to first compile the code before it can be run. We can use the `@time` macro to see this effect. (If you run the cell more than once the effect will go away since it has already been compiled!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(1000);\n",
    "function sum_global()\n",
    "    s = 0.0\n",
    "    for i in x\n",
    "        s += i\n",
    "    end\n",
    "    return s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000235 seconds (3.49 k allocations: 70.156 KiB)\n",
      "  0.000131 seconds (3.49 k allocations: 70.156 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time sum_global();\n",
    "@time sum_global();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro is convenient, but only executes the function once. We can use the `BenchmarkTools.jl` library to investigate the performance of our function with multiple trials. The `@benchmark` macro will run 10,000 trials or (roughly) 5 seconds whichever comes first. (These can be configured). There is also the `@btime` macro which runs the same number of trials as `@benchmark` but has output similar to `@time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m74.900 μs\u001b[22m\u001b[39m … \u001b[35m 1.511 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 91.95%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m77.900 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m81.754 μs\u001b[22m\u001b[39m ± \u001b[32m54.465 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m2.50% ±  3.57%\n",
       "\n",
       "  \u001b[39m▂\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[32m▆\u001b[39m\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m \u001b[39m█\n",
       "  74.9 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       109 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m70.16 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3490\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@benchmark sum_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function takes parameters, be sure to \"interpolate\" them with a `$` when using `@benchmark` this tells `BenchmarkTools.jl` to ignore the allocation and time required to allocate the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.060 μs (4 allocations: 3.59 KiB)\n",
      "  1.360 μs (5 allocations: 3.95 KiB)\n"
     ]
    }
   ],
   "source": [
    "# Parameter is Interpolated\n",
    "@btime inv($(rand(6,6)));\n",
    "# No Interpolation\n",
    "@btime inv(rand(6,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Memory Allocations\n",
    "One of the easiest ways to speed up your code is by removing all unnecessary memory allocations. In Python the end-user is not able to manage memory easily and the interprer or library (e.g. numpy) is trusted to handle things.\n",
    "\n",
    "Julia can also operate like Python, where we just trust the compiler to \"do the right thing\". This is good for prototyping, but can result in inefficient code. Below we will look at the basics of memory allocations and how to reduce them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "Lets start by allocating a small array of 10,000 Float64s. Each Float64 is 8 bytes (64 bits), so the total size should be 80,000 bytes or 80kB (78.125 kiB). Note there will be a slight overhead for some internal machinery associated with each allocation (e.g. a pointer to the array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000040 seconds (2 allocations: 78.172 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time ones(Float64, 100, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Julia all arrays are `heap` allocated since they are re-sizeable. This just means that the array is further away from the CPU and it can be slow(er) to allocate and access. The first strategy to mitigate this penalty is to simply allocate memory as little as possible. To check this we can use our `BenchmarkTools.jl` library to understand the allocations in our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allocates_once (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function allocates_alot()\n",
    "    res = 0.0\n",
    "    for i in 1:100\n",
    "        x = rand(100,100) # ALLOCATION EVERY LOOP ITERATION\n",
    "        res += sum(x)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "function allocates_once()\n",
    "    res = 0.0\n",
    "    storage = zeros(100,100)\n",
    "    for i in 1:100\n",
    "        #The ! point means it mutates the input\n",
    "        # In this case it over writes storage with new random values\n",
    "        rand!(storage)\n",
    "        res += sum(storage)\n",
    "    end\n",
    "    return res\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `@btime` macro we can measure the performace uplift and the number of allocations from each function. You'll find that the function which allocates a new array each loop iteration will be slower and allocate far more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  845.800 μs (200 allocations: 7.63 MiB)\n",
      "  409.200 μs (2 allocations: 78.17 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime allocates_alot() samples = 1000;\n",
    "@btime allocates_once() samples = 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more subtle, yet common place where allocations occur is array slices (e.g. `arr[1:10]`). In Julia these slices allocate a new array by default. We can get around this by telling Julia that we only want to read the data inside the arr. To do this we use an `array view` which can be acheive with the `view(...)` function or the `@views` macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_macro_slices (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function slices_allocate(x)\n",
    "    N = Int(length(x) / 2)\n",
    "    res = sum(x[1:N])\n",
    "    return res\n",
    "end\n",
    "\n",
    "function view_slices(x)\n",
    "    N = Int(length(x) / 2)\n",
    "    #The view function takes the array\n",
    "    # and the indicies you want a view of.\n",
    "    res = sum(view(x, 1:N))\n",
    "    return res\n",
    "end\n",
    "\n",
    "function view_macro_slices(x)\n",
    "    N = Int(length(x) / 2)\n",
    "    # The @views macro tells Julia all array slices in\n",
    "    # this line should be array views.\n",
    "    @views res = sum(x[1:N])\n",
    "    return res\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see a large speed increase and the number of allocations drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  57.700 μs (3 allocations: 390.69 KiB)\n",
      "  5.317 μs (1 allocation: 16 bytes)\n",
      "  5.333 μs (1 allocation: 16 bytes)\n"
     ]
    }
   ],
   "source": [
    "x = rand(100000)\n",
    "@btime slices_allocate(x) samples = 1000;\n",
    "@btime view_slices(x) samples = 1000;\n",
    "@btime view_macro_slices(x) samples = 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StaticArrays\n",
    "Earlier we mentioned that Julia arrays are `heap` allocated because they have variable length (i.e., you can append to them). If you know the length of your array beforehand, you can use the `StaticArrays.jl` library to `stack` allocate your data (if its small enough).\n",
    "\n",
    "`StaticArrays.jl` has many types you can use, but the main types are `SVector` for 1D arrays, `SMatrix` for 2D arrays, and `SArray` for n-dimensional arrays (all types have equivalent macros e.g., `@SMatrix`).\n",
    "\n",
    "To initialize a NxN `SMatrix` we must provide the size to the constructor: `SMatrix{N,N}(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SMatrix{25,25}(rand(25,25));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern in atomistic simulation packages is to have an array of `SVectors` which represent atomic properties, like their position. Storing the data for each atom as an SVector can be much faster than using the default Julia array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_matrix (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_atoms = 1000\n",
    "static_positions = [SVector{3}(rand(3)) for i in 1:N_atoms];\n",
    "dynamic_positions = [rand(3) for i in 1:N_atoms];\n",
    "\n",
    "function distance_matrix(positions)\n",
    "    N = length(positions)\n",
    "    dists = zeros(N,N)\n",
    "    for i in 1:N\n",
    "        for j in i:N\n",
    "            dists[i,j] = norm(positions[i] - positions[j])\n",
    "            dists[j,i] = dists[i,j]\n",
    "        end\n",
    "    end\n",
    "    return dists\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Vector Benchmark:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1402 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.898 ms\u001b[22m\u001b[39m … \u001b[35m13.290 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 33.18%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.024 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m3.559 ms\u001b[22m\u001b[39m ± \u001b[32m 1.227 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m15.11% ± 19.44%\n",
       "\n",
       "  \u001b[39m \u001b[39m█\u001b[34m▅\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▅\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m▂\n",
       "  2.9 ms\u001b[90m         Histogram: frequency by time\u001b[39m         6.3 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m7.63 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"Static Vector Benchmark:\")\n",
    "@benchmark distance_matrix(static_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Array Benchmark:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 156 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m30.954 ms\u001b[22m\u001b[39m … \u001b[35m50.233 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m6.95% … 9.65%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m31.861 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m7.91%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m32.131 ms\u001b[22m\u001b[39m ± \u001b[32m 1.785 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m7.96% ± 0.37%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m█\u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m▃\u001b[32m▃\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m▇\u001b[39m▅\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m \u001b[39m▅\n",
       "  31 ms\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      37.2 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m45.81 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m500502\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"Dynamic Array Benchmark:\")\n",
    "@benchmark distance_matrix(dynamic_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Stability\n",
    "Julia will do its best to infer the data types of your variables, but if the compiler cannot infer the type of all your variables this leads to type instability and will slow down your code. We can check type stability with the `@code_warntype` macro. For today's purposes if this macro returns any red text then your code has unstable types.\n",
    "\n",
    "In the example below, the functions are equivalent except one relies on a gloabl variable and the other takes that variable as a parameter. Because of the global variable, the compiler must assume that the variables inside the `unstable` function have `Any` type. Whereas in the type stable code the compiler can create a specialized version of the `stable` function for the specific type you passed into it. This is not the only unstable pattern, so if you really care about speed check your code with `@code_warntype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stable (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_x = rand(Float64, 1000)\n",
    "function unstable()\n",
    "    s = 0\n",
    "    for val in global_x\n",
    "      s = s + val\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "function stable(x)\n",
    "  s = zero(eltype(x))\n",
    "  for val in x\n",
    "     s = s + val\n",
    "  end\n",
    "  return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for unstable()\n",
      "  from unstable()\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90mc:\\Users\\ejmei\\repos\\MolSSI_workshop\\\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sZmlsZQ==.jl:2\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(unstable)\u001b[39m\n",
      "Locals\n",
      "  @_2\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  s\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  val\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "Body\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m       (s = 0)\n",
      "\u001b[90m│  \u001b[39m %2  = Main.global_x\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_2 = Base.iterate(%2))\n",
      "\u001b[90m│  \u001b[39m %4  = (@_2 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %5  = Base.not_int(%4)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %5\n",
      "\u001b[90m2 ┄\u001b[39m %7  = @_2\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (val = Core.getfield(%7, 1))\n",
      "\u001b[90m│  \u001b[39m %9  = Core.getfield(%7, 2)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (s = s + val)\n",
      "\u001b[90m│  \u001b[39m       (@_2 = Base.iterate(%2, %9))\n",
      "\u001b[90m│  \u001b[39m %12 = (@_2 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %13 = Base.not_int(%12)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %13\n",
      "\u001b[90m3 ─\u001b[39m       goto #2\n",
      "\u001b[90m4 ┄\u001b[39m       return s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@code_warntype unstable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for stable(::Vector{Float64})\n",
      "  from stable(\u001b[90mx\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90mc:\\Users\\ejmei\\repos\\MolSSI_workshop\\\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sZmlsZQ==.jl:10\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(stable)\u001b[39m\n",
      "  x\u001b[36m::Vector{Float64}\u001b[39m\n",
      "Locals\n",
      "  @_3\u001b[33m\u001b[1m::Union{Nothing, Tuple{Float64, Int64}}\u001b[22m\u001b[39m\n",
      "  s\u001b[36m::Float64\u001b[39m\n",
      "  val\u001b[36m::Float64\u001b[39m\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1  = Main.eltype(x)\u001b[36m::Core.Const(Float64)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (s = Main.zero(%1))\n",
      "\u001b[90m│  \u001b[39m %3  = x\u001b[36m::Vector{Float64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_3 = Base.iterate(%3))\n",
      "\u001b[90m│  \u001b[39m %5  = (@_3 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %6  = Base.not_int(%5)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %6\n",
      "\u001b[90m2 ┄\u001b[39m %8  = @_3\u001b[36m::Tuple{Float64, Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (val = Core.getfield(%8, 1))\n",
      "\u001b[90m│  \u001b[39m %10 = Core.getfield(%8, 2)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (s = s + val)\n",
      "\u001b[90m│  \u001b[39m       (@_3 = Base.iterate(%3, %10))\n",
      "\u001b[90m│  \u001b[39m %13 = (@_3 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %14 = Base.not_int(%13)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %14\n",
      "\u001b[90m3 ─\u001b[39m       goto #2\n",
      "\u001b[90m4 ┄\u001b[39m       return s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@code_warntype stable(global_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  76.000 μs (3490 allocations: 70.16 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime unstable();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  930.000 ns (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime stable($global_x);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
