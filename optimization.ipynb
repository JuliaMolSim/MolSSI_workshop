{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "This notebook will cover techniques for going from \"Julia code that runs\" to \"Julia code that runs *fast*(er)!\"\n",
    "\n",
    "Another useful \"one-stop-shop\" resource in this category (there are many more!) is the [Optimization post on Modern Julia Workflows](https://modernjuliaworkflows.org/optimizing/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using StaticArrays\n",
    "using Random\n",
    "using Plots\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia is just in time (JIT) compiled, so the first time you run code there will be a penalty to first compile the code before it can be run. We can use the `@time` macro to see this effect. (If you run the cell more than once, the effect will go away since it has already been compiled!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(1000);\n",
    "function sum_global()\n",
    "    s = 0.0\n",
    "    for i in x\n",
    "        s += i\n",
    "    end\n",
    "    return s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time sum_global();\n",
    "@time sum_global();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro is convenient, but only executes the function once. We can use the [BenchmarkTools](https://juliaci.github.io/BenchmarkTools.jl/stable/) library to investigate the performance of our function with multiple trials. The `@benchmark` macro will run 10,000 trials or (roughly) 5 seconds whichever comes first. (These can be configured). There is also the `@btime` macro which runs the same number of trials as `@benchmark` but has output similar to `@time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark sum_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function takes parameters, be sure to \"interpolate\" them with a `$` when using `@benchmark` this tells BenchmarkTools to ignore the allocation and time required to allocate the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter is Interpolated\n",
    "@btime inv($(rand(6,6)));\n",
    "# No Interpolation\n",
    "@btime inv(rand(6,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Memory Allocations\n",
    "One of the easiest ways to speed up your code is by removing all unnecessary memory allocations. In Python the end-user is not able to manage memory easily and the interprer or library (e.g. numpy) is trusted to handle things.\n",
    "\n",
    "Julia can also operate like Python, where we just trust the compiler to \"do the right thing\". This is good for prototyping, but can result in inefficient code. Below we will look at the basics of memory allocations and how to reduce them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "Lets start by allocating a small array of 10,000 `Float64`s. Each `Float64` is 8 bytes (64 bits), so the total size should be 80,000 bytes or 80kB (78.125 kiB). Note there will be a slight overhead for some internal machinery associated with each allocation (e.g. a pointer to the array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time ones(Float64, 100, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Julia all arrays are `heap` allocated since they are re-sizeable. This just means that the array is further away from the CPU and it can be slow(er) to allocate and access. The first strategy to mitigate this penalty is to simply allocate memory as little as possible. To check this we can use BenchmarkTools to understand the allocations in our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function allocates_alot()\n",
    "    res = 0.0\n",
    "    for i in 1:100\n",
    "        x = rand(100,100) # ALLOCATION EVERY LOOP ITERATION\n",
    "        res += sum(x)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "function allocates_once()\n",
    "    res = 0.0\n",
    "    storage = zeros(100,100)\n",
    "    for i in 1:100\n",
    "        # The ! point means it mutates the input\n",
    "        # In this case it over writes storage with new random values\n",
    "        rand!(storage)\n",
    "        res += sum(storage)\n",
    "    end\n",
    "    return res\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `@btime` macro, we can measure the performace uplift and the number of allocations from each function. You'll find that the function which allocates a new array each loop iteration will be slower and allocate far more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime allocates_alot() samples = 1000;\n",
    "@btime allocates_once() samples = 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more subtle, yet very common place where allocations occur is array slices (e.g. `arr[1:10]`). In Julia, these slices allocate a new array by default. We can get around this by telling Julia that we only want to read the data inside the arr. To do this we use an \"array view\" which can be acheived with the `view(...)` function or the `@views` macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function slices_allocate(x)\n",
    "    N = Int(length(x) / 2)\n",
    "    res = sum(x[1:N])\n",
    "    return res\n",
    "end\n",
    "\n",
    "function view_slices(x)\n",
    "    N = Int(length(x) / 2)\n",
    "    #The view function takes the array\n",
    "    # and the indicies you want a view of.\n",
    "    res = sum(view(x, 1:N))\n",
    "    return res\n",
    "end\n",
    "\n",
    "function view_macro_slices(x)\n",
    "    N = Int(length(x) / 2)\n",
    "    # The @views macro tells Julia all array slices in\n",
    "    # this line should be array views.\n",
    "    @views res = sum(x[1:N])\n",
    "    return res\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see a large speed increase and the number of allocations drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(100000)\n",
    "@btime slices_allocate(x) samples = 1000;\n",
    "@btime view_slices(x) samples = 1000;\n",
    "@btime view_macro_slices(x) samples = 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StaticArrays\n",
    "Earlier, we mentioned that Julia arrays are `heap` allocated because they have variable length (i.e., you can append to them). If you know the length of your array beforehand, you can use the [StaticArrays](https://juliaarrays.github.io/StaticArrays.jl/stable/) library to `stack` allocate your data (if its small enough).\n",
    "\n",
    "StaticArrays has many types you can use, but the main types are `SVector` for 1D arrays, `SMatrix` for 2D arrays, and `SArray` for n-dimensional arrays (all types have equivalent macros e.g., `@SMatrix`).\n",
    "\n",
    "To initialize a NxN `SMatrix` we must provide the size to the constructor: `SMatrix{N,N}(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SMatrix{25,25}(rand(25,25));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern in atomistic simulation packages is to have an array of `SVectors` which represent atomic properties, like their position. Storing the data for each atom as an SVector can be much faster than using the default Julia array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_atoms = 1000\n",
    "static_positions = [SVector{3}(rand(3)) for i in 1:N_atoms];\n",
    "dynamic_positions = [rand(3) for i in 1:N_atoms];\n",
    "\n",
    "function distance_matrix(positions)\n",
    "    N = length(positions)\n",
    "    dists = zeros(N,N)\n",
    "    for i in 1:N\n",
    "        for j in i:N\n",
    "            dists[i,j] = norm(positions[i] - positions[j])\n",
    "            dists[j,i] = dists[i,j]\n",
    "        end\n",
    "    end\n",
    "    return dists\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Static Vector Benchmark:\")\n",
    "@benchmark distance_matrix(static_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Dynamic Array Benchmark:\")\n",
    "@benchmark distance_matrix(dynamic_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `SVector`s etc. are statically sized and immutable. The StaticArrays package also provides statically sized but mutable variants, which are prefixed with `M` instead of `S`, e.g. `SMatrix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Stability\n",
    "Julia will do its best to infer the data types of your variables, but if the compiler cannot infer the type of all your variables this leads to type instability and will slow down your code. We can check type stability with the `@code_warntype` macro. For today's purposes, if this macro returns any red text, then your code has unstable types.\n",
    "\n",
    "In the example below, the functions are equivalent except one relies on a gloabl variable and the other takes that variable as a parameter. Because of the global variable, the compiler must assume that the variables inside the *unstable* function have `Any` type. Whereas in the type-stable code, the compiler can create a specialized version of the stable function for the specific type you passed into it. This is not the only unstable pattern, so if you really care about speed, check your code with `@code_warntype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_x = rand(Float64, 1000)\n",
    "function unstable()\n",
    "    s = 0\n",
    "    for val in global_x\n",
    "      s = s + val\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "function stable(x)\n",
    "  s = zero(eltype(x))\n",
    "  for val in x\n",
    "     s = s + val\n",
    "  end\n",
    "  return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_warntype unstable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_warntype stable(global_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime unstable();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime stable($global_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
