{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "# using OhMyThreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Threading\n",
    "Julia's default `Threads` library provides the `Threads.@threads` macro to turn any for loop into a parallel for loop. To change the number of threads Julia has access to we can define the environment variable `JULIA_NUM_THREADS`. This must be done before starting the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Julia has access to \", Threads.nthreads(), \" threads\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function single_thread!(vals)\n",
    "    for i in eachindex(vals)\n",
    "        vals[i] = sqrt(vals[i])*sqrt(vals[i])\n",
    "    end\n",
    "    return vals\n",
    "end\n",
    "\n",
    "function all_threads!(vals)\n",
    "    Threads.@threads :static for i in eachindex(vals)\n",
    "        vals[i] = sqrt(vals[i])*sqrt(vals[i])\n",
    "    end\n",
    "    return vals\n",
    "end\n",
    "\n",
    "function broadcasted!(vals)\n",
    "    vals .= sqrt.(vals).*sqrt.(vals)\n",
    "    return vals\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = abs.(rand(1000000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark single_thread!($vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark broadcasted!($vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark all_threads!($vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's `Threads` library does not let you set the number of tasks, to do that we can use the `OhMyThreads.jl` library. In `OhMyThreads` the `Threads.@threads` macro is replaced with the `@tasks` macro inside of which we can set certain properties like `ntasks` or the type of thread scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ohmythreads!(vals, n_threads = Threads.nthreads())\n",
    "    @tasks for i in eachindex(vals)\n",
    "        @set ntasks = n_threads\n",
    "        @set scheduler = :static\n",
    "        vals[i] = sqrt(vals[i])*sqrt(vals[i])\n",
    "    end\n",
    "    return vals\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark ohmythreads!(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Array Programming\n",
    "With the power of dynamic dispath we can perform many operations on the GPU just by changing the type of our data from `Array` to `CuArray` (or the analagous type for AMD, Intel, or Apple). For the purposes of the workshop, we cannot assume everyone will have a GPU available to run on, so I will just demonstrate how easy it is to get your code running on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example is for CUDA but is the same principle for all the GPU libraries\n",
    "#using CUDA or AMDGPU or oneAPI or Metal or KernelAbstractions\n",
    "\n",
    "# Moving data from CPU to GPU.\n",
    "A = rand(3,3)\n",
    "cu_B = CuArray{Float32}(A)\n",
    "\n",
    "# Can also pre-allocate storage on the GPU and copy data to it.\n",
    "gpu_storage = CUDA.zeros(Float32, 3, 3)\n",
    "gpu_array2 = copyto!(cu_B, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we multiply cu_B by itself this multiplcation will take place on the GPU automatically because the type of cu_B is a `CuArray`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_C = cu_B * cu_B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more high-level functions that \"just work\" on the GPU. For example, all unary operations like `+,-,*` have GPU implementations. There are also abstractions such as `reduce` and `mapreduce` which allow you to apply an operation or function across an array. Note that all high-level GPU operations should act on an entire array and not a single element at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_C = CUDA.rand(5)\n",
    "sum_of_C = sum(cu_C)\n",
    "sum_of_C_also = reduce(+, cu_C)\n",
    "\n",
    "f = (x) -> x^2\n",
    "C_squared = map(f, cu_C)\n",
    "sum_of_C_squared = mapreduce(f, +, cu_C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
